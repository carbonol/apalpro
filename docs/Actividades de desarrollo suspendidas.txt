
1 - Implementación de la funcionalidad de evaluación:
a) Crear 1 usuario con rol de profesor

b) Crear 1 ejercicio con sus respectivos casos de prueba - Algunos casos de prueba serán visibles al estudiante, mientras que otros estarán ocultos.
b*) USUALMENTE, se debe autenticar que el usuario que haga esta petición sea un profesor, porque sólo un profesor puede crear ejercicios con casos de prueba.

c) Crear 1 usuario con rol de estudiante

d) Ver los datos de un ejercicio, según id, sólo con los casos de prueba visibles. 
(ALTERNATIVA DESCARTADA: Otra alternativa sería enviar los datos de un ejercicio con todos los casos de prueba, y que la aplicación cliente valide cuáles casos de prueba son visibles para el usuario - Esto ahorraría recursos de servidor para procesar evaluaciones porque ya no sería necesario obtener todos los casos de prueba desde el servidor, sino que esta información sería proporcionado por el cliente. Si no, habría que obtener dos veces los casos de prueba de la base de datos desde el servidor: Una petición para que el estudiante sólo vea los casos de prueba visibles, y otra, cuando se hace la evaluación, de todos los casos de prueba del ejercicio. Pero, esto podría hacer más insegura a la aplicación, en cuanto a que no se validarían si los casos de prueba dados por la aplicación cliente son los casos de prueba que realmente se deberían evaluar.)

e) Crear (registrar) 1 propuesta de solución (COMO ESTUDIANTE) para un problema, que no cumpla con al menos un caso de prueba y almacenar los datos de la evaluación de la misma.
f) Crear (registrar) 1 propuesta de solución (COMO ESTUDIANTE) para un problema, que sí cumpla con al menos un caso de prueba y almacenar los datos de la evaluación de la misma.
Tanto en c) como en d) es particularmente importante desarrollar la lógica del proceso de envío y evaluación de una propuesta de solución:
Cuando el usuario (usualmente un estudiante) envía una propuesta de solución (en Python 3):
I) Se toma el código escrito en Python 3, el id del usuario (sea estudiante, profesor o administrador) y el id del ejercicio para que estos datos sean procesados en la aplicación web
II) La aplicación web debe, entonces, ordenar la ejecución de un intérprete de Python 3 que evalúe la propuesta de solución (código) del usuario que envió el usuario por medio de la comprobación del cumplimiento de este código de todos los casos de prueba (entradas - salidas) descritos para el ejercicio. Esto implica:
i) Asegurarse de que los datos de id de usuario y id de ejercicio existan. Si no, devuelva un mensaje al usuario diciendo que se requiere el id de usuario y el id de ejercicio para realizar la evaluación. NOTA: El código puede estar vacío (sin caracteres), y esto es válido (aunque la evaluación en este caso, muy seguramente, será desfavorable para el estudiante)
ii) Crear el registro en base de datos de la propuesta de solución, ingresando el id del usuario y el código - El registro created_at muestra la fecha de cuándo se hizo esto. Asimismo, se debe referenciar el id de la propuesta de solución para algunos de los pasos posteriores de este proceso.
iii) Internamente, obtener los datos de los casos de prueba que han sido asignados al ejercicio, con base en el id del ejercicio.
iv) Si se encontraron casos de prueba, crear el archivo .py correspondiente al código enviado por el estudiante en el servidor. Si no, devuelva un mensaje diciendo que no existen casos de prueba para el problema dado.
PERO: Hay diferentes usuarios: Crear un directorio por usuario, y colocar el archivo .py en este directorio. (Nota: Sólo se debería hacer, máximo, 1 evaluación a la vez, por cliente, para evitar conflictos entre evaluación y evaluación).
v) Ejecutar los n casos de prueba del ejercicio => Así que el programa .py se ejecutará n veces en el servidor, pero cada vez, con datos de entrada diferentes, según el caso de prueba a evaluar. PARA CADA CASO DE PRUEBA: Se deben obtener los datos de salida (texto) del programa .py. Luego, se van almacenando los datos de evaluación del caso de prueba en la base de datos: id de la propuesta de solución, id del caso de prueba, salida producida por el programa, y el resultado final de la evaluación, conforme a la comparación de los textos de salida esperada del caso de prueba y la salida que produjo el programa, el cual puede ser OK o NO OK.
vi) Al finalizar la ejecución, elimine el archivo .py (y el directorio del usuario), y almacene el resultado final de evaluación de la solución propuesta en la base de datos, mirando los resultados OK y NO OK obtenidos en los casos de prueba: Si todos son OK, almacene OK; si no, almacene NO OK.
vii) Si este proceso es exitoso, haga COMMIT en la base de datos; si hay una excepción (fallo) durante cualquier parte del proceso, y ya se ha almacenado información (temporalmente) en la base de datos, haga ROLLBACK para deshacer los cambios.

NOTA: Debe configurarse un directorio, desde el servidor, en donde se irán procesando los archivos .py y evaluando los casos de prueba correspondientes.

2 - Configuración del resto de la arquitectura de la aplicación web Java (Lógica del modelo y controlador):
Implementación de las clases DAO (Modelo), Resources (Controlador), así como la clase SQLQueries.java en co.com.aprosoft.apalpro.model.utils.

3 - Interfaz de usuario (Frontend)